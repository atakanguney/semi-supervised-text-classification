{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from unicode_tr import unicode_tr\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from math import log, inf\n",
    "from operator import itemgetter\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"semi-supervised-pytorch/semi-supervised\")\n",
    "from models import ProdLDADeepGenerativeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = TurkishStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findfiles(path,flist):\n",
    "    dirs = os.listdir(path)\n",
    "    for df in dirs:\n",
    "        if os.path.isdir(path+\"/\"+df):\n",
    "            findfiles(path+\"/\"+df,flist)\n",
    "        else:\n",
    "            flist.append(path+\"/\"+df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/42bin_haber/news'\n",
    "categories = os.listdir(path)[:]\n",
    "categories = ['ekonomi','kultur-sanat','magazin','saglik','siyaset','spor','teknoloji']\n",
    "news_files = {}\n",
    "for cat in categories:\n",
    "    flist = []\n",
    "    findfiles(path+\"/\"+cat,flist)\n",
    "    news_files[cat] = flist[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(words,stop_words = stopwords.words('turkish'),url_regex=None):\n",
    "    #Remove URLS\n",
    "    if url_regex:\n",
    "        words = [word for word in words if not re.match(url_regex,word)]\n",
    "\n",
    "    #Remove trash characters\n",
    "    words = [re.sub(\"\\xad|\\x95|\\x80|\\x82|\\x93|\\x94|\\x91|\\x92|\\x96|^\\'+|^\\*+|^-+|\\'+$\", \"\", word) for word in words]\n",
    "\n",
    "    #Remove nonalphanumeric\n",
    "    words = [word for word in words if not re.match(\"\\W\", word)]\n",
    "\n",
    "    #Lower all words\n",
    "    words = [unicode_tr(word.strip()).lower() for word in words if word.strip()!=\"\"]\n",
    "    \n",
    "    #Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    #Stemming\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_corpus = {}\n",
    "test_files = {}\n",
    "all_words = []\n",
    "X = []\n",
    "y = []\n",
    "for cat in categories:\n",
    "    print(cat)\n",
    "    for f in news_files[cat]:\n",
    "        with open(f) as file:\n",
    "            lines = file.readlines()\n",
    "            lines = ''.join(lines)\n",
    "\n",
    "            words = word_tokenize(lines)\n",
    "            words = preprocess(words)\n",
    "\n",
    "            X.append(words)\n",
    "            y.append(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\" \".join(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = CountVectorizer(max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_all = dtm.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_scores = calc_representativeness_scores(docs_all, tokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dtm.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "encoded_labels = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes, = np.where(encoded_labels == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes_to_remove = np.random.choice(idxes, 5000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.delete(encoded_labels, idxes_to_remove), bins=[-0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(encoded_labels, bins=[-0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "labels = ohe.fit_transform(np.expand_dims(encoded_labels, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_all = docs_all.todense()\n",
    "labels = labels.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_all = np.delete(docs_all, idxes_to_remove, axis=0)\n",
    "labels = np.delete(labels, idxes_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_scores = np.delete(repr_scores, idxes_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ids = np.arange(len(docs_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid, row_ids_train, row_ids_valid= train_test_split(docs_all, labels, row_ids, test_size=0.20)\n",
    "x_labelled, x_unlabelled, y_labelled, y_unlabelled, row_ids_labelled, row_ids_unlabelled = train_test_split(X_train, y_train, row_ids_train, train_size=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labelled.shape, x_unlabelled.shape, y_labelled.shape, y_unlabelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(data, batch_size):\n",
    "    x, y = data\n",
    "    batch_idx = np.random.choice(x.shape[0], batch_size, replace=False)\n",
    "\n",
    "    return torch.from_numpy(x[batch_idx]).float(), torch.from_numpy(y[batch_idx]).float()\n",
    "\n",
    "def create_data_sets(labelled, unlabelled, batch_size):\n",
    "    num_labelled = labelled[0].shape[0]\n",
    "    num_unlabelled = unlabelled[0].shape[0]\n",
    "\n",
    "    train_labelled = [create_batch(labelled, batch_size) for _ in range(num_labelled // batch_size)]\n",
    "    train_unlabelled = [create_batch(unlabelled, batch_size) for _ in range(num_unlabelled // batch_size)]\n",
    "    \n",
    "    return train_labelled, train_unlabelled\n",
    "\n",
    "def create_validation_set(validation, batch_size):\n",
    "    num_validation = validation[0].shape[0]\n",
    "    \n",
    "    validation = [create_batch(validation, batch_size) for _ in range(num_validation // batch_size)]\n",
    "    \n",
    "    return validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled, unlabelled = (x_labelled, y_labelled), (x_unlabelled, y_unlabelled)\n",
    "validation = create_validation_set((X_valid, y_valid), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_samples(num_mc_samples, model, x_batch):\n",
    "    model.train()\n",
    "    mc_samples_ = [model.classify(x_batch) for _ in range(num_mc_samples)]\n",
    "    return torch.stack(mc_samples_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bald_acq(mc_samples):\n",
    "    #expected_entropy = -(mc_samples * (mc_samples + 1e-10).log()).sum(dim=-1).mean(dim=0)  # [batch size]\n",
    "    expected_entropy = -np.mean(np.sum(mc_samples * np.log(mc_samples + 1e-10), axis=-1), axis=0)\n",
    "    #expected_p = mc_samples.mean(dim=0)\n",
    "    expected_p = np.mean(mc_samples, axis=0)\n",
    "    #entropy_expected_p = - (expected_p * (expected_p + 1e-10).log()).sum(dim=-1)  # [batch size]\n",
    "    entropy_expected_p = - np.sum(expected_p * np.log(expected_p + 1e-10), axis=-1)\n",
    "\n",
    "    BALD_acq = entropy_expected_p - expected_entropy\n",
    "    \n",
    "    return BALD_acq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_new_data(num_data, num_mc_samples, model, unlabelled_data, batch_size):\n",
    "    num_samples = unlabelled_data.shape[0]\n",
    "    batch_results = []\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        unlabelled_data_batch = torch.from_numpy(unlabelled_data[i:i+batch_size]).float()\n",
    "        if cuda:\n",
    "            unlabelled_data_batch = unlabelled_data_batch.cuda()\n",
    "        mc_samples_ = mc_samples(num_mc_samples, model, unlabelled_data_batch).cpu().detach().numpy()\n",
    "        bald_acq_ = bald_acq(mc_samples_)\n",
    "        batch_results.append(bald_acq_)\n",
    "        #sorted_, indices = bald_acq_.sort()\n",
    "    \n",
    "    bald_acq_ = np.hstack(batch_results)\n",
    "    indices = bald_acq_.argsort()\n",
    "    return indices[::-1][:num_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dim = len(categories)\n",
    "z_dim = 50\n",
    "h_dim = [50, 50]\n",
    "\n",
    "num_topics = y_dim\n",
    "a = 1.0\n",
    "prior_mean = np.log(a) - np.mean(np.log(a))\n",
    "prior_var = (((1.0 / a) * (1 - (2.0 / num_topics))) + (1.0 / (num_topics * num_topics)) * np.sum((1.0 / a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(in_dim, y_dim, z_dim, h_dim, prior_mean, prior_var):\n",
    "    model = ProdLDADeepGenerativeModel([in_dim, y_dim, z_dim, h_dim], prior_mean, prior_var)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import SVI, ImportanceWeightedSampler\n",
    "from itertools import cycle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def train_semi_supervised(model, labelled, unlabelled, validation, cuda, epochs=4):\n",
    "    # You can use importance weighted samples [Burda, 2015] to get a better estimate\n",
    "    # on the log-likelihood.\n",
    "    sampler = ImportanceWeightedSampler(mc=1, iw=1)\n",
    "\n",
    "    def binary_cross_entropy(r, x):\n",
    "        return -torch.sum(x * torch.log(r + 1e-8) + (1 - x) * torch.log(1 - r + 1e-8), dim=-1)\n",
    "\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "    elbo = SVI(model, likelihood=binary_cross_entropy, sampler=sampler)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))\n",
    "\n",
    "\n",
    "    if cuda: \n",
    "        model = model.cuda()\n",
    "\n",
    "    alpha = 1.0 * len(unlabelled) / len(labelled)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, accuracy = (0, 0)\n",
    "        for (x, y), (u, _) in zip(cycle(labelled), unlabelled):\n",
    "            #x, y, u = torch.from_numpy(x).float(), torch.from_numpy(y).float(), torch.from_numpy(u).float()\n",
    "            # Wrap in variables\n",
    "            x, y, u = Variable(x), Variable(y), Variable(u)\n",
    "\n",
    "            if cuda:\n",
    "                # They need to be on the same device and be synchronized.\n",
    "                x, y = x.cuda(device=1), y.cuda(device=1)\n",
    "                u = u.cuda(device=1)\n",
    "\n",
    "            # print(x.sum())\n",
    "            L = -elbo(x, y)\n",
    "            U = -elbo(u)\n",
    "\n",
    "            # Add auxiliary classification loss q(y|x)\n",
    "            logits = model.classify(x)\n",
    "\n",
    "            # Regular cross entropy\n",
    "            classication_loss = torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "            J_alpha = L - alpha * classication_loss + U\n",
    "\n",
    "            J_alpha.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += J_alpha.data.item()\n",
    "            accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            model.eval()\n",
    "            m = len(unlabelled)\n",
    "            print(\"Epoch: {}\".format(epoch))\n",
    "            print(\"[Train]\\t\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n",
    "\n",
    "            total_loss, accuracy = (0, 0)\n",
    "            for x, y in validation:\n",
    "                x, y = Variable(x), Variable(y)\n",
    "\n",
    "                if cuda:\n",
    "                    x, y = x.cuda(device=1), y.cuda(device=1)\n",
    "\n",
    "                L = -elbo(x, y)\n",
    "                U = -elbo(x)\n",
    "\n",
    "                logits = model.classify(x)\n",
    "                classication_loss = -torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "                J_alpha = L + alpha * classication_loss + U\n",
    "\n",
    "                total_loss += J_alpha.data.item()\n",
    "\n",
    "                _, pred_idx = torch.max(logits, 1)\n",
    "                _, lab_idx = torch.max(y, 1)\n",
    "                accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "            m = len(validation)\n",
    "            print(\"[Validation]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n",
    "            \n",
    "    return total_loss / m, accuracy / m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MC_SAMPLES = 10\n",
    "NUM_QUERY = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearange_datasets(labelled, unlabelled, new_data):\n",
    "    labelled_x, labelled_y = labelled\n",
    "    unlabelled_x, unlabelled_y = unlabelled\n",
    "    \n",
    "    new_data_x, new_data_y = unlabelled_x[new_data], unlabelled_y[new_data]\n",
    "    \n",
    "    new_labelled_x = np.append(labelled_x, new_data_x, axis=0)\n",
    "    new_labelled_y = np.append(labelled_y, new_data_y, axis=0)\n",
    "    \n",
    "    new_unlabelled_x = np.delete(unlabelled_x, new_data, axis=0)\n",
    "    new_unlabelled_y = np.delete(unlabelled_y, new_data, axis=0)\n",
    "    \n",
    "    return (new_labelled_x, new_labelled_y), (new_unlabelled_x, new_unlabelled_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvolutionalClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalClassifier, self).__init__()        \n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=4)\n",
    "\n",
    "        size = int((x_dim - 3) + 1)//4\n",
    "        size = int((size - 3) + 1)//4\n",
    "                \n",
    "        self.fc1 = nn.Linear(32*size, 50)\n",
    "        self.fc2 = nn.Linear(50, 7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, *_ = x.size()\n",
    "        x = x.view(-1, 1, x_dim)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(x.view(batch, -1))\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=-1)\n",
    "\n",
    "classifier = ConvolutionalClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "batch_size=50\n",
    "for i in range(50):\n",
    "    model = initialize_model(x_dim, y_dim, z_dim, h_dim, prior_mean, prior_var)\n",
    "    #classifier = ConvolutionalClassifier()\n",
    "    #model.classifier = classifier\n",
    "    train_labelled, train_unlabelled = create_data_sets(labelled, unlabelled, batch_size)\n",
    "    \n",
    "    print(labelled[0].shape[0], unlabelled[0].shape[0])\n",
    "    error, acc = train_semi_supervised(model, train_labelled, train_unlabelled, validation, cuda, epochs=10)\n",
    "    errors.append((labelled[0].shape[0], unlabelled[0].shape[0], error, acc))\n",
    "    \n",
    "    new_data = query_new_data(NUM_QUERY, NUM_MC_SAMPLES, model, unlabelled[0], batch_size)\n",
    "    labelled, unlabelled = rearange_datasets(labelled, unlabelled, new_data)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labelled = []\n",
    "num_unlabelled = []\n",
    "cost = []\n",
    "acc = []\n",
    "\n",
    "for n_l, n_u, c, a in errors:\n",
    "    num_labelled.append(n_l)\n",
    "    num_unlabelled.append(n_u)\n",
    "    cost.append(c)\n",
    "    acc.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(num_labelled, cost)\n",
    "plt.xlabel(\"Number of labelled data\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.savefig(\"n_labelled_vs_cost-turkish_news.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(num_labelled, acc)\n",
    "plt.xlabel(\"Number of labelled data\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.savefig(\"n_labelled_vs_acc-turkish_news.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_2 = [(n_l, n_u, c, a.item()) for n_l, n_u, c, a in errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"TN-data-erros.pkl\", \"wb\") as f:\n",
    "    pickle.dump(errors_2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representativeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "def add_vector_sparse(X,v):\n",
    "    rows, cols = X.shape\n",
    "    row_start_stop = np.lib.stride_tricks.as_strided(X.indptr, shape=(rows, 2),\n",
    "                            strides=2*X.indptr.strides)\n",
    "    for row, (start, stop) in enumerate(row_start_stop):\n",
    "        data = X.data[start:stop]\n",
    "        data += v[row]\n",
    "\n",
    "def calc_representativeness_scores(corpus, lambda_=0.9, B=0.3, tokenized=False):\n",
    "    \n",
    "    if tokenized:\n",
    "        X = corpus\n",
    "    else:\n",
    "        vectorizer = CountVectorizer()\n",
    "        X = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    D = X.shape[0]\n",
    "    \n",
    "    p_w = X.sum(axis=0) / X.sum()\n",
    "    p_w_given_d_i = normalize(X, norm='l1', axis=1)\n",
    "    \n",
    "    log_p_w = np.log(p_w)\n",
    "    dist_disjoint = p_w_given_d_i.dot((1-lambda_) * log_p_w.T)\n",
    "    \n",
    "    p_w = np.squeeze(np.asarray(p_w))\n",
    "    \n",
    "    log_p_w_given_d_i = p_w_given_d_i.transpose().copy()\n",
    "\n",
    "    log_p_w_given_d_i.data = lambda_*log_p_w_given_d_i.data \n",
    "    add_vector_sparse(log_p_w_given_d_i, lambda_*p_w)\n",
    "\n",
    "    log_p_w_given_d_i.data = np.log(log_p_w_given_d_i.data)\n",
    "    add_vector_sparse(log_p_w_given_d_i, -(1-lambda_)*np.log(p_w))\n",
    "    \n",
    "    log_p_w_given_d_i = log_p_w_given_d_i.transpose()\n",
    "    \n",
    "    dist_common = p_w_given_d_i.dot(log_p_w_given_d_i.sum(axis=0).T)\n",
    "    \n",
    "    dist_common = np.squeeze(np.asarray(dist_common))\n",
    "    dist_disjoint = np.squeeze(np.asarray(dist_disjoint))\n",
    "    \n",
    "    dist_all = dist_common + dist_disjoint\n",
    "    \n",
    "    entropy = p_w_given_d_i.copy()\n",
    "    entropy.data = p_w_given_d_i.data*np.log(p_w_given_d_i.data)\n",
    "\n",
    "    entropy = np.squeeze(np.asarray(entropy.sum(axis=1)))\n",
    "    \n",
    "    kl_sum = dist_all - D * entropy\n",
    "    kl_sum *= (B / D) \n",
    "    z_i = np.exp(kl_sum)\n",
    "    \n",
    "    return z_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_new_data(num_data, num_mc_samples, model, unlabelled_data, repr_scores=None):\n",
    "    unlabelled_data = torch.from_numpy(unlabelled_data).float()\n",
    "    if cuda:\n",
    "        unlabelled_data = unlabelled_data.cuda()\n",
    "    mc_samples_ = mc_samples(num_mc_samples, model, unlabelled_data).cpu().detach().numpy()\n",
    "    bald_acq_ = bald_acq(mc_samples_)\n",
    "    \n",
    "    if repr_scores is not None:\n",
    "        bald_acq_ = bald_acq_ * repr_scores\n",
    "    #sorted_, indices = bald_acq_.sort()\n",
    "    indices = bald_acq_.argsort()\n",
    "    return indices[::-1][:num_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "batch_size=50\n",
    "for i in range(50):\n",
    "    model = initialize_model(x_dim, y_dim, z_dim, h_dim, prior_mean, prior_var)\n",
    "    #classifier = ConvolutionalClassifier()\n",
    "    #model.classifier = classifier\n",
    "    train_labelled, train_unlabelled = create_data_sets(labelled, unlabelled, batch_size)\n",
    "    \n",
    "    print(labelled[0].shape[0], unlabelled[0].shape[0])\n",
    "    error, acc = train_semi_supervised(model, train_labelled, train_unlabelled, validation, cuda, epochs=5)\n",
    "    errors.append((labelled[0].shape[0], unlabelled[0].shape[0], error, acc))\n",
    "    \n",
    "    new_data = query_new_data(NUM_QUERY, NUM_MC_SAMPLES, model, unlabelled[0], repr_scores=repr_scores[row_ids_unlabelled])\n",
    "    #new_data = np.random.choice(unlabelled[0].shape[0], NUM_QUERY)\n",
    "    row_ids_unlabelled = np.delete(row_ids_unlabelled, new_data, axis=0)\n",
    "    labelled, unlabelled = rearange_datasets(labelled, unlabelled, new_data)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labelled = []\n",
    "num_unlabelled = []\n",
    "cost = []\n",
    "acc = []\n",
    "\n",
    "for n_l, n_u, c, a in errors:\n",
    "    num_labelled.append(n_l)\n",
    "    num_unlabelled.append(n_u)\n",
    "    cost.append(c)\n",
    "    acc.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(num_labelled, cost)\n",
    "plt.xlabel(\"Number of labelled data\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.savefig(\"n_labelled_vs_cost-turkish_news-represent.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(num_labelled, acc)\n",
    "plt.xlabel(\"Number of labelled data\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.savefig(\"n_labelled_vs_acc-turkish_news-represent.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_2 = [(n_l, n_u, c, a.item()) for n_l, n_u, c, a in errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"plots/TN-data-erros-represent.pkl\", \"wb\") as f:\n",
    "    pickle.dump(errors_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
