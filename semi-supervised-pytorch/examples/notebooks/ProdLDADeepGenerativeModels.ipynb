{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../../semi-supervised\")\n",
    "from models import ProdLDADeepGenerativeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dim = 2\n",
    "z_dim = 100\n",
    "h_dim = [100, 100]\n",
    "\n",
    "num_topics = y_dim\n",
    "a = 1.0\n",
    "prior_mean = np.log(a) - np.mean(np.log(a))\n",
    "prior_var = (((1.0 / a) * (1 - (2.0 / num_topics))) + (1.0 / (num_topics * num_topics)) * np.sum((1.0 / a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(in_dim, y_dim, z_dim, h_dim, prior_mean, prior_var):\n",
    "    model = ProdLDADeepGenerativeModel([in_dim, y_dim, z_dim, h_dim], prior_mean, prior_var)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import SVI, ImportanceWeightedSampler\n",
    "from itertools import cycle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def train_semi_supervised(model, labelled, unlabelled, validation, cuda, epochs=4):\n",
    "    # You can use importance weighted samples [Burda, 2015] to get a better estimate\n",
    "    # on the log-likelihood.\n",
    "    sampler = ImportanceWeightedSampler(mc=1, iw=1)\n",
    "\n",
    "    def binary_cross_entropy(r, x):\n",
    "        return -torch.sum(x * torch.log(r + 1e-8) + (1 - x) * torch.log(1 - r + 1e-8), dim=-1)\n",
    "\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "    elbo = SVI(model, likelihood=binary_cross_entropy, sampler=sampler)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))\n",
    "\n",
    "\n",
    "    if cuda: \n",
    "        model = model.cuda()\n",
    "\n",
    "    alpha = 1.0 * len(unlabelled) / len(labelled)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, accuracy = (0, 0)\n",
    "        for (x, y), (u, _) in zip(cycle(labelled), unlabelled):\n",
    "            #x, y, u = torch.from_numpy(x).float(), torch.from_numpy(y).float(), torch.from_numpy(u).float()\n",
    "            # Wrap in variables\n",
    "            x, y, u = Variable(x), Variable(y), Variable(u)\n",
    "\n",
    "            if cuda:\n",
    "                # They need to be on the same device and be synchronized.\n",
    "                x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "                u = u.cuda(device=0)\n",
    "\n",
    "            # print(x.sum())\n",
    "            L = -elbo(x, y)\n",
    "            U = -elbo(u)\n",
    "\n",
    "            # Add auxiliary classification loss q(y|x)\n",
    "            logits = model.classify(x)\n",
    "\n",
    "            # Regular cross entropy\n",
    "            classication_loss = torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "            J_alpha = L - alpha * classication_loss + U\n",
    "\n",
    "            J_alpha.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += J_alpha.data.item()\n",
    "            accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            model.eval()\n",
    "            m = len(unlabelled)\n",
    "            print(\"Epoch: {}\".format(epoch))\n",
    "            print(\"[Train]\\t\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n",
    "\n",
    "            total_loss, accuracy = (0, 0)\n",
    "            for x, y in validation:\n",
    "                x, y = Variable(x), Variable(y)\n",
    "\n",
    "                if cuda:\n",
    "                    x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "\n",
    "                L = -elbo(x, y)\n",
    "                U = -elbo(x)\n",
    "\n",
    "                logits = model.classify(x)\n",
    "                classication_loss = -torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "                J_alpha = L + alpha * classication_loss + U\n",
    "\n",
    "                total_loss += J_alpha.data.item()\n",
    "\n",
    "                _, pred_idx = torch.max(logits, 1)\n",
    "                _, lab_idx = torch.max(y, 1)\n",
    "                accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "            m = len(validation)\n",
    "            print(\"[Validation]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n",
    "            \n",
    "    return total_loss / m, accuracy / m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representativeness Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "def add_vector_sparse(X,v):\n",
    "    rows, cols = X.shape\n",
    "    row_start_stop = np.lib.stride_tricks.as_strided(X.indptr, shape=(rows, 2),\n",
    "                            strides=2*X.indptr.strides)\n",
    "    for row, (start, stop) in enumerate(row_start_stop):\n",
    "        data = X.data[start:stop]\n",
    "        data += v[row]\n",
    "\n",
    "def calc_representativeness_scores(corpus, lambda_=0.9, B=0.3, tokenized=False):\n",
    "    \n",
    "    if tokenized:\n",
    "        X = corpus\n",
    "    else:\n",
    "        vectorizer = CountVectorizer()\n",
    "        X = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    D = X.shape[0]\n",
    "    \n",
    "    p_w = X.sum(axis=0) / X.sum()\n",
    "    p_w_given_d_i = normalize(X, norm='l1', axis=1)\n",
    "    \n",
    "    log_p_w = np.log(p_w)\n",
    "    dist_disjoint = p_w_given_d_i.dot((1-lambda_) * log_p_w.T)\n",
    "    \n",
    "    p_w = np.squeeze(np.asarray(p_w))\n",
    "    \n",
    "    log_p_w_given_d_i = p_w_given_d_i.transpose().copy()\n",
    "\n",
    "    log_p_w_given_d_i.data = lambda_*log_p_w_given_d_i.data \n",
    "    add_vector_sparse(log_p_w_given_d_i, lambda_*p_w)\n",
    "\n",
    "    log_p_w_given_d_i.data = np.log(log_p_w_given_d_i.data)\n",
    "    add_vector_sparse(log_p_w_given_d_i, -(1-lambda_)*np.log(p_w))\n",
    "    \n",
    "    log_p_w_given_d_i = log_p_w_given_d_i.transpose()\n",
    "    \n",
    "    dist_common = p_w_given_d_i.dot(log_p_w_given_d_i.sum(axis=0).T)\n",
    "    \n",
    "    dist_common = np.squeeze(np.asarray(dist_common))\n",
    "    dist_disjoint = np.squeeze(np.asarray(dist_disjoint))\n",
    "    \n",
    "    dist_all = dist_common + dist_disjoint\n",
    "    \n",
    "    entropy = p_w_given_d_i.copy()\n",
    "    entropy.data = p_w_given_d_i.data*np.log(p_w_given_d_i.data)\n",
    "\n",
    "    entropy = np.squeeze(np.asarray(entropy.sum(axis=1)))\n",
    "    \n",
    "    kl_sum = dist_all - D * entropy\n",
    "    kl_sum *= (B / D) \n",
    "    z_i = np.exp(kl_sum)\n",
    "    \n",
    "    return z_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_samples(num_mc_samples, model, x_batch):\n",
    "    model.train()\n",
    "    mc_samples_ = [model.classify(x_batch) for _ in range(num_mc_samples)]\n",
    "    return torch.stack(mc_samples_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bald_acq(mc_samples):\n",
    "    #expected_entropy = -(mc_samples * (mc_samples + 1e-10).log()).sum(dim=-1).mean(dim=0)  # [batch size]\n",
    "    expected_entropy = -np.mean(np.sum(mc_samples * np.log(mc_samples + 1e-10), axis=-1), axis=0)\n",
    "    #expected_p = mc_samples.mean(dim=0)\n",
    "    expected_p = np.mean(mc_samples, axis=0)\n",
    "    #entropy_expected_p = - (expected_p * (expected_p + 1e-10).log()).sum(dim=-1)  # [batch size]\n",
    "    entropy_expected_p = - np.sum(expected_p * np.log(expected_p + 1e-10), axis=-1)\n",
    "\n",
    "    BALD_acq = entropy_expected_p - expected_entropy\n",
    "    \n",
    "    return BALD_acq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_new_data(num_data, num_mc_samples, model, unlabelled_data, repr_scores=None):\n",
    "    unlabelled_data = torch.from_numpy(unlabelled_data).float()\n",
    "    if cuda:\n",
    "        unlabelled_data = unlabelled_data.cuda()\n",
    "    mc_samples_ = mc_samples(num_mc_samples, model, unlabelled_data).cpu().detach().numpy()\n",
    "    bald_acq_ = bald_acq(mc_samples_)\n",
    "    \n",
    "    if repr_scores is not None:\n",
    "        bald_acq_ = bald_acq_ * repr_scores\n",
    "    #sorted_, indices = bald_acq_.sort()\n",
    "    indices = bald_acq_.argsort()\n",
    "    return indices[::-1][:num_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/atakanguney94/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading positives...\n",
      "2500 / 12500\n",
      "5000 / 12500\n",
      "7500 / 12500\n",
      "10000 / 12500\n",
      "12500 / 12500\n",
      "Reading negatives...\n",
      "2500 / 12500\n",
      "5000 / 12500\n",
      "7500 / 12500\n",
      "10000 / 12500\n",
      "12500 / 12500\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "\n",
    "\n",
    "X_ = []\n",
    "y_ = []\n",
    "\n",
    "pos_path = \"./data/aclImdb/train/pos/\"\n",
    "poses = os.listdir(pos_path)[:]\n",
    "pos_path + poses[0]\n",
    "\n",
    "print(\"Reading positives...\")\n",
    "counter = 1\n",
    "for f in poses:\n",
    "    if counter%2500 == 0:\n",
    "        print(counter,\"/\", len(poses))\n",
    "    counter += 1\n",
    "    \n",
    "    with open(pos_path + f) as file:\n",
    "        lines = file.readlines()\n",
    "        lines = ''.join(lines)\n",
    "\n",
    "        #words = word_tokenize(lines)\n",
    "        X_.append(lines)\n",
    "        y_.append(1)\n",
    "        \n",
    "\n",
    "neg_path = \"./data/aclImdb/train/neg/\"\n",
    "negs = os.listdir(neg_path)[:]\n",
    "\n",
    "print(\"Reading negatives...\")\n",
    "counter = 1\n",
    "for f in negs:\n",
    "    if counter%2500 == 0:\n",
    "        print(counter, \"/\", len(negs))\n",
    "    counter += 1\n",
    "    \n",
    "    with open(neg_path + f) as file:\n",
    "        lines = file.readlines()\n",
    "        lines = ''.join(lines)\n",
    "\n",
    "        #words = word_tokenize(lines)\n",
    "        X_.append(lines)\n",
    "        y_.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = CountVectorizer(stop_words=\"english\", max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = tf.fit_transform(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_scores = calc_representativeness_scores(docs, tokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ids =np.arange(len(X_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = len(tf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atakanguney94/.virtualenvs/ML/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "labels = ohe.fit_transform(np.expand_dims(y_, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid, row_ids_train, row_ids_valid = train_test_split(docs, labels, row_ids, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atakanguney94/.virtualenvs/ML/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_labelled, x_unlabelled, y_labelled, y_unlabelled, row_ids_labelled, row_ids_unlabelled = train_test_split(X_train, y_train, row_ids_train, train_size=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 10000), (19600, 10000), (400, 2), (19600, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_labelled.shape, x_unlabelled.shape, y_labelled.shape, y_unlabelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(data, batch_size):\n",
    "    x, y = data\n",
    "    batch_idx = np.random.choice(x.shape[0], batch_size, replace=False)\n",
    "\n",
    "    return torch.from_numpy(x[batch_idx]).float(), torch.from_numpy(y[batch_idx]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_sets(labelled, unlabelled, batch_size):\n",
    "    num_labelled = labelled[0].shape[0]\n",
    "    num_unlabelled = unlabelled[0].shape[0]\n",
    "\n",
    "    train_labelled = [create_batch(labelled, batch_size) for _ in range(num_labelled // batch_size)]\n",
    "    train_unlabelled = [create_batch(unlabelled, batch_size) for _ in range(num_unlabelled // batch_size)]\n",
    "    \n",
    "    return train_labelled, train_unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_set(validation, batch_size):\n",
    "    num_validation = validation[0].shape[0]\n",
    "    \n",
    "    validation = [create_batch(validation, batch_size) for _ in range(num_validation // batch_size)]\n",
    "    \n",
    "    return validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled, unlabelled = (x_labelled, y_labelled), (x_unlabelled, y_unlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labelled, train_unlabelled = create_data_sets(labelled, unlabelled, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = create_validation_set((X_valid, y_valid), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MC_SAMPLES = 10\n",
    "NUM_QUERY = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearange_datasets(labelled, unlabelled, new_data):\n",
    "    labelled_x, labelled_y = labelled\n",
    "    unlabelled_x, unlabelled_y = unlabelled\n",
    "    \n",
    "    new_data_x, new_data_y = unlabelled_x[new_data], unlabelled_y[new_data]\n",
    "    \n",
    "    new_labelled_x = np.append(labelled_x, new_data_x, axis=0)\n",
    "    new_labelled_y = np.append(labelled_y, new_data_y, axis=0)\n",
    "    \n",
    "    new_unlabelled_x = np.delete(unlabelled_x, new_data, axis=0)\n",
    "    new_unlabelled_y = np.delete(unlabelled_y, new_data, axis=0)\n",
    "    \n",
    "    return (new_labelled_x, new_labelled_y), (new_unlabelled_x, new_unlabelled_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_labelled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-668b94a9f69d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labelled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_labelled' is not defined"
     ]
    }
   ],
   "source": [
    "len(train_labelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 19600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../semi-supervised/models/prodlda.py:57: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.activation(x)\n",
      "../../semi-supervised/models/prodlda.py:65: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.output_activation(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2075.56, accuracy: 0.99\n",
      "[Validation]\t J_a: 2211.55, accuracy: 0.50\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 1928.45, accuracy: 1.00\n",
      "[Validation]\t J_a: 2260.55, accuracy: 0.49\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 1855.08, accuracy: 1.00\n",
      "[Validation]\t J_a: 2295.59, accuracy: 0.49\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1789.36, accuracy: 1.00\n",
      "[Validation]\t J_a: 2298.19, accuracy: 0.49\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1734.71, accuracy: 1.00\n",
      "[Validation]\t J_a: 2258.45, accuracy: 0.49\n",
      "600 19400\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2044.33, accuracy: 0.99\n",
      "[Validation]\t J_a: 2228.18, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 1891.79, accuracy: 1.00\n",
      "[Validation]\t J_a: 2278.49, accuracy: 0.51\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 1807.79, accuracy: 1.00\n",
      "[Validation]\t J_a: 2291.58, accuracy: 0.51\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1758.34, accuracy: 1.00\n",
      "[Validation]\t J_a: 2302.85, accuracy: 0.51\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1720.97, accuracy: 1.00\n",
      "[Validation]\t J_a: 2260.01, accuracy: 0.51\n",
      "800 19200\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2048.72, accuracy: 0.98\n",
      "[Validation]\t J_a: 2153.78, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 1878.49, accuracy: 1.00\n",
      "[Validation]\t J_a: 2160.61, accuracy: 0.51\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 1829.27, accuracy: 1.00\n",
      "[Validation]\t J_a: 2156.79, accuracy: 0.51\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1784.11, accuracy: 1.00\n",
      "[Validation]\t J_a: 2144.38, accuracy: 0.51\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1742.92, accuracy: 1.00\n",
      "[Validation]\t J_a: 2123.77, accuracy: 0.51\n",
      "1000 19000\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2026.39, accuracy: 0.97\n",
      "[Validation]\t J_a: 2125.38, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 1866.77, accuracy: 1.00\n",
      "[Validation]\t J_a: 2169.15, accuracy: 0.51\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 1821.12, accuracy: 1.00\n",
      "[Validation]\t J_a: 2217.97, accuracy: 0.51\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1784.97, accuracy: 1.00\n",
      "[Validation]\t J_a: 2192.39, accuracy: 0.51\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1748.21, accuracy: 1.00\n",
      "[Validation]\t J_a: 2204.08, accuracy: 0.51\n",
      "1200 18800\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2035.96, accuracy: 0.94\n",
      "[Validation]\t J_a: 2178.45, accuracy: 0.49\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 1869.46, accuracy: 1.00\n",
      "[Validation]\t J_a: 2206.28, accuracy: 0.49\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 1819.45, accuracy: 1.00\n",
      "[Validation]\t J_a: 2287.07, accuracy: 0.49\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1777.73, accuracy: 1.00\n",
      "[Validation]\t J_a: 2391.02, accuracy: 0.50\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1740.57, accuracy: 1.00\n",
      "[Validation]\t J_a: 3167.91, accuracy: 0.49\n",
      "1400 18600\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2087.70, accuracy: 0.96\n",
      "[Validation]\t J_a: 2078.72, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 1905.78, accuracy: 1.00\n",
      "[Validation]\t J_a: 2110.38, accuracy: 0.50\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 1859.41, accuracy: 1.00\n",
      "[Validation]\t J_a: 2083.35, accuracy: 0.50\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1823.44, accuracy: 1.00\n",
      "[Validation]\t J_a: 2144.31, accuracy: 0.50\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1793.12, accuracy: 1.00\n",
      "[Validation]\t J_a: 2136.26, accuracy: 0.50\n",
      "1600 18400\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2113.21, accuracy: 0.93\n",
      "[Validation]\t J_a: 2091.26, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 1968.78, accuracy: 1.00\n",
      "[Validation]\t J_a: 2116.47, accuracy: 0.51\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 1892.74, accuracy: 1.00\n",
      "[Validation]\t J_a: 2144.24, accuracy: 0.51\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1842.04, accuracy: 1.00\n",
      "[Validation]\t J_a: 2115.74, accuracy: 0.51\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1806.70, accuracy: 1.00\n",
      "[Validation]\t J_a: 2069.03, accuracy: 0.51\n",
      "1800 18200\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2151.02, accuracy: 0.87\n",
      "[Validation]\t J_a: 2093.09, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 1988.43, accuracy: 1.00\n",
      "[Validation]\t J_a: 2239.72, accuracy: 0.52\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 1937.22, accuracy: 1.00\n",
      "[Validation]\t J_a: 2192.56, accuracy: 0.52\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1895.04, accuracy: 1.00\n",
      "[Validation]\t J_a: 2224.03, accuracy: 0.52\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1856.25, accuracy: 1.00\n",
      "[Validation]\t J_a: 2333.56, accuracy: 0.52\n",
      "2000 18000\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2174.74, accuracy: 0.91\n",
      "[Validation]\t J_a: 2018.60, accuracy: 0.50\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2018.65, accuracy: 0.99\n",
      "[Validation]\t J_a: 1977.83, accuracy: 0.50\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 1958.04, accuracy: 1.00\n",
      "[Validation]\t J_a: 1958.92, accuracy: 0.50\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1919.35, accuracy: 1.00\n",
      "[Validation]\t J_a: 1973.64, accuracy: 0.50\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1883.30, accuracy: 1.00\n",
      "[Validation]\t J_a: 2044.17, accuracy: 0.50\n",
      "2200 17800\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2220.55, accuracy: 0.86\n",
      "[Validation]\t J_a: 2066.45, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2054.81, accuracy: 0.99\n",
      "[Validation]\t J_a: 2477.69, accuracy: 0.52\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2001.82, accuracy: 1.00\n",
      "[Validation]\t J_a: 2035.83, accuracy: 0.52\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1965.59, accuracy: 1.00\n",
      "[Validation]\t J_a: 1987.54, accuracy: 0.52\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1935.84, accuracy: 1.00\n",
      "[Validation]\t J_a: 1962.67, accuracy: 0.52\n",
      "2400 17600\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2244.31, accuracy: 0.86\n",
      "[Validation]\t J_a: 2073.23, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2072.67, accuracy: 0.99\n",
      "[Validation]\t J_a: 2093.02, accuracy: 0.52\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2022.76, accuracy: 1.00\n",
      "[Validation]\t J_a: 2031.15, accuracy: 0.51\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1986.10, accuracy: 1.00\n",
      "[Validation]\t J_a: 2065.16, accuracy: 0.51\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1954.52, accuracy: 1.00\n",
      "[Validation]\t J_a: 2043.41, accuracy: 0.51\n",
      "2600 17400\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2310.88, accuracy: 0.86\n",
      "[Validation]\t J_a: 2042.68, accuracy: 0.59\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2172.57, accuracy: 0.95\n",
      "[Validation]\t J_a: 1994.39, accuracy: 0.59\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2093.19, accuracy: 0.99\n",
      "[Validation]\t J_a: 1955.09, accuracy: 0.58\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2030.42, accuracy: 0.99\n",
      "[Validation]\t J_a: 1905.94, accuracy: 0.58\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1984.11, accuracy: 1.00\n",
      "[Validation]\t J_a: 1882.08, accuracy: 0.57\n",
      "2800 17200\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2356.19, accuracy: 0.90\n",
      "[Validation]\t J_a: 2050.02, accuracy: 0.66\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2205.88, accuracy: 0.98\n",
      "[Validation]\t J_a: 1983.14, accuracy: 0.59\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2127.28, accuracy: 0.98\n",
      "[Validation]\t J_a: 1942.03, accuracy: 0.53\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2066.76, accuracy: 0.99\n",
      "[Validation]\t J_a: 1903.69, accuracy: 0.53\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2024.87, accuracy: 1.00\n",
      "[Validation]\t J_a: 1869.97, accuracy: 0.53\n",
      "3000 17000\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2349.93, accuracy: 0.79\n",
      "[Validation]\t J_a: 2063.76, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2200.54, accuracy: 0.96\n",
      "[Validation]\t J_a: 2018.07, accuracy: 0.52\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2119.56, accuracy: 0.99\n",
      "[Validation]\t J_a: 1977.22, accuracy: 0.52\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2068.89, accuracy: 1.00\n",
      "[Validation]\t J_a: 1948.14, accuracy: 0.53\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2020.24, accuracy: 1.00\n",
      "[Validation]\t J_a: 1919.93, accuracy: 0.53\n",
      "3200 16800\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2391.93, accuracy: 0.80\n",
      "[Validation]\t J_a: 2062.81, accuracy: 0.60\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2250.12, accuracy: 0.92\n",
      "[Validation]\t J_a: 1988.00, accuracy: 0.61\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2175.46, accuracy: 0.97\n",
      "[Validation]\t J_a: 1956.93, accuracy: 0.60\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2114.11, accuracy: 0.99\n",
      "[Validation]\t J_a: 1940.13, accuracy: 0.61\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2064.76, accuracy: 0.99\n",
      "[Validation]\t J_a: 1865.42, accuracy: 0.60\n",
      "3400 16600\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2404.08, accuracy: 0.78\n",
      "[Validation]\t J_a: 2013.19, accuracy: 0.50\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2236.11, accuracy: 0.94\n",
      "[Validation]\t J_a: 1969.67, accuracy: 0.51\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2176.37, accuracy: 0.99\n",
      "[Validation]\t J_a: 1930.40, accuracy: 0.52\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2141.19, accuracy: 1.00\n",
      "[Validation]\t J_a: 1924.36, accuracy: 0.52\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2106.85, accuracy: 1.00\n",
      "[Validation]\t J_a: 1917.36, accuracy: 0.52\n",
      "3600 16400\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2382.74, accuracy: 0.78\n",
      "[Validation]\t J_a: 1997.61, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2240.59, accuracy: 0.93\n",
      "[Validation]\t J_a: 1960.00, accuracy: 0.52\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2177.56, accuracy: 0.99\n",
      "[Validation]\t J_a: 1932.46, accuracy: 0.52\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2140.99, accuracy: 1.00\n",
      "[Validation]\t J_a: 1914.87, accuracy: 0.52\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2108.03, accuracy: 1.00\n",
      "[Validation]\t J_a: 1900.09, accuracy: 0.52\n",
      "3800 16200\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2416.29, accuracy: 0.69\n",
      "[Validation]\t J_a: 2039.30, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2248.85, accuracy: 0.93\n",
      "[Validation]\t J_a: 2214.83, accuracy: 0.52\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2185.68, accuracy: 0.98\n",
      "[Validation]\t J_a: 2021.85, accuracy: 0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2149.29, accuracy: 0.99\n",
      "[Validation]\t J_a: 2005.60, accuracy: 0.52\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2118.33, accuracy: 1.00\n",
      "[Validation]\t J_a: 2046.98, accuracy: 0.52\n",
      "4000 16000\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2397.73, accuracy: 0.78\n",
      "[Validation]\t J_a: 1995.58, accuracy: 0.55\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2249.78, accuracy: 0.88\n",
      "[Validation]\t J_a: 1944.50, accuracy: 0.52\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2171.93, accuracy: 0.97\n",
      "[Validation]\t J_a: 1930.42, accuracy: 0.53\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2131.61, accuracy: 0.99\n",
      "[Validation]\t J_a: 1919.01, accuracy: 0.52\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2101.05, accuracy: 1.00\n",
      "[Validation]\t J_a: 1901.22, accuracy: 0.52\n",
      "4200 15800\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2451.03, accuracy: 0.65\n",
      "[Validation]\t J_a: 2055.88, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2302.60, accuracy: 0.88\n",
      "[Validation]\t J_a: 2008.09, accuracy: 0.54\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2220.57, accuracy: 0.97\n",
      "[Validation]\t J_a: 2177.15, accuracy: 0.54\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2181.01, accuracy: 0.99\n",
      "[Validation]\t J_a: 2091.85, accuracy: 0.53\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2151.12, accuracy: 1.00\n",
      "[Validation]\t J_a: 2049.85, accuracy: 0.53\n",
      "4400 15600\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2427.63, accuracy: 0.78\n",
      "[Validation]\t J_a: 2049.94, accuracy: 0.58\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2287.54, accuracy: 0.85\n",
      "[Validation]\t J_a: 1945.08, accuracy: 0.54\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2210.43, accuracy: 0.90\n",
      "[Validation]\t J_a: 1894.70, accuracy: 0.53\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2153.80, accuracy: 0.96\n",
      "[Validation]\t J_a: 1864.19, accuracy: 0.54\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2111.91, accuracy: 0.98\n",
      "[Validation]\t J_a: 1835.59, accuracy: 0.54\n",
      "4600 15400\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2450.02, accuracy: 0.72\n",
      "[Validation]\t J_a: 2000.97, accuracy: 0.53\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2302.10, accuracy: 0.91\n",
      "[Validation]\t J_a: 2016.76, accuracy: 0.56\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2237.54, accuracy: 0.98\n",
      "[Validation]\t J_a: 2055.82, accuracy: 0.56\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2200.04, accuracy: 0.99\n",
      "[Validation]\t J_a: 1991.12, accuracy: 0.56\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2169.57, accuracy: 1.00\n",
      "[Validation]\t J_a: 2033.22, accuracy: 0.55\n",
      "4800 15200\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2430.71, accuracy: 0.72\n",
      "[Validation]\t J_a: 2005.49, accuracy: 0.53\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2288.79, accuracy: 0.87\n",
      "[Validation]\t J_a: 1960.04, accuracy: 0.54\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2222.30, accuracy: 0.96\n",
      "[Validation]\t J_a: 1927.65, accuracy: 0.54\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2186.17, accuracy: 0.99\n",
      "[Validation]\t J_a: 1905.48, accuracy: 0.55\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2154.35, accuracy: 0.99\n",
      "[Validation]\t J_a: 1875.71, accuracy: 0.55\n",
      "5000 15000\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2435.35, accuracy: 0.63\n",
      "[Validation]\t J_a: 2044.75, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2284.41, accuracy: 0.85\n",
      "[Validation]\t J_a: 2206.79, accuracy: 0.54\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2217.13, accuracy: 0.96\n",
      "[Validation]\t J_a: 3516.91, accuracy: 0.54\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2179.07, accuracy: 0.98\n",
      "[Validation]\t J_a: 2943.02, accuracy: 0.55\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2148.24, accuracy: 0.99\n",
      "[Validation]\t J_a: 3773.83, accuracy: 0.55\n",
      "5200 14800\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2436.00, accuracy: 0.60\n",
      "[Validation]\t J_a: 2046.68, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2308.50, accuracy: 0.80\n",
      "[Validation]\t J_a: 2001.77, accuracy: 0.53\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2240.25, accuracy: 0.91\n",
      "[Validation]\t J_a: 1938.16, accuracy: 0.54\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2179.38, accuracy: 0.96\n",
      "[Validation]\t J_a: 1904.91, accuracy: 0.54\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2136.97, accuracy: 0.98\n",
      "[Validation]\t J_a: 1871.54, accuracy: 0.54\n",
      "5400 14600\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2464.94, accuracy: 0.63\n",
      "[Validation]\t J_a: 2054.76, accuracy: 0.53\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2302.63, accuracy: 0.80\n",
      "[Validation]\t J_a: 2053.32, accuracy: 0.54\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2216.70, accuracy: 0.93\n",
      "[Validation]\t J_a: 2034.24, accuracy: 0.55\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2178.41, accuracy: 0.97\n",
      "[Validation]\t J_a: 2016.76, accuracy: 0.55\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2150.34, accuracy: 0.99\n",
      "[Validation]\t J_a: 1984.82, accuracy: 0.55\n",
      "5600 14400\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2446.96, accuracy: 0.58\n",
      "[Validation]\t J_a: 2054.48, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2301.40, accuracy: 0.78\n",
      "[Validation]\t J_a: 1996.13, accuracy: 0.53\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2221.23, accuracy: 0.91\n",
      "[Validation]\t J_a: 1953.76, accuracy: 0.54\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2177.26, accuracy: 0.96\n",
      "[Validation]\t J_a: 1932.31, accuracy: 0.54\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2144.46, accuracy: 0.98\n",
      "[Validation]\t J_a: 1895.82, accuracy: 0.55\n",
      "5800 14200\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2452.65, accuracy: 0.67\n",
      "[Validation]\t J_a: 2034.58, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2293.18, accuracy: 0.73\n",
      "[Validation]\t J_a: 1979.90, accuracy: 0.55\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2205.49, accuracy: 0.90\n",
      "[Validation]\t J_a: 2259.82, accuracy: 0.56\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2166.41, accuracy: 0.94\n",
      "[Validation]\t J_a: 2300.26, accuracy: 0.56\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2137.17, accuracy: 0.97\n",
      "[Validation]\t J_a: 1966.09, accuracy: 0.55\n",
      "6000 14000\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2423.88, accuracy: 0.62\n",
      "[Validation]\t J_a: 2034.63, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2283.17, accuracy: 0.77\n",
      "[Validation]\t J_a: 1983.85, accuracy: 0.54\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2214.25, accuracy: 0.91\n",
      "[Validation]\t J_a: 1962.80, accuracy: 0.54\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2170.33, accuracy: 0.96\n",
      "[Validation]\t J_a: 1955.60, accuracy: 0.55\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2140.59, accuracy: 0.98\n",
      "[Validation]\t J_a: 1928.86, accuracy: 0.55\n",
      "6200 13800\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2406.51, accuracy: 0.53\n",
      "[Validation]\t J_a: 2058.36, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2269.41, accuracy: 0.73\n",
      "[Validation]\t J_a: 1997.12, accuracy: 0.54\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2181.94, accuracy: 0.89\n",
      "[Validation]\t J_a: 2101.02, accuracy: 0.55\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2140.16, accuracy: 0.95\n",
      "[Validation]\t J_a: 2000.41, accuracy: 0.55\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2112.07, accuracy: 0.98\n",
      "[Validation]\t J_a: 2134.32, accuracy: 0.55\n",
      "6400 13600\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2397.26, accuracy: 0.66\n",
      "[Validation]\t J_a: 2057.48, accuracy: 0.59\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2268.10, accuracy: 0.76\n",
      "[Validation]\t J_a: 1986.04, accuracy: 0.60\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2210.70, accuracy: 0.86\n",
      "[Validation]\t J_a: 1958.40, accuracy: 0.61\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2164.13, accuracy: 0.92\n",
      "[Validation]\t J_a: 1921.06, accuracy: 0.61\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2115.13, accuracy: 0.95\n",
      "[Validation]\t J_a: 1877.23, accuracy: 0.61\n",
      "6600 13400\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2384.38, accuracy: 0.56\n",
      "[Validation]\t J_a: 2051.24, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2239.15, accuracy: 0.71\n",
      "[Validation]\t J_a: 1995.15, accuracy: 0.54\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2168.30, accuracy: 0.88\n",
      "[Validation]\t J_a: 2100.08, accuracy: 0.55\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2125.30, accuracy: 0.93\n",
      "[Validation]\t J_a: 1994.93, accuracy: 0.56\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2096.81, accuracy: 0.97\n",
      "[Validation]\t J_a: 1951.35, accuracy: 0.56\n",
      "6800 13200\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2356.77, accuracy: 0.55\n",
      "[Validation]\t J_a: 2055.91, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2234.54, accuracy: 0.73\n",
      "[Validation]\t J_a: 2012.48, accuracy: 0.54\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2157.18, accuracy: 0.89\n",
      "[Validation]\t J_a: 1972.01, accuracy: 0.56\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2118.07, accuracy: 0.94\n",
      "[Validation]\t J_a: 1964.03, accuracy: 0.55\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2090.16, accuracy: 0.97\n",
      "[Validation]\t J_a: 1952.56, accuracy: 0.56\n",
      "7000 13000\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2361.76, accuracy: 0.65\n",
      "[Validation]\t J_a: 2024.65, accuracy: 0.54\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2211.04, accuracy: 0.70\n",
      "[Validation]\t J_a: 1955.07, accuracy: 0.55\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2133.84, accuracy: 0.83\n",
      "[Validation]\t J_a: 1933.06, accuracy: 0.57\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2095.08, accuracy: 0.91\n",
      "[Validation]\t J_a: 1908.96, accuracy: 0.57\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2067.16, accuracy: 0.95\n",
      "[Validation]\t J_a: 1887.10, accuracy: 0.57\n",
      "7200 12800\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2334.79, accuracy: 0.58\n",
      "[Validation]\t J_a: 2029.44, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2207.89, accuracy: 0.74\n",
      "[Validation]\t J_a: 1963.88, accuracy: 0.55\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2135.57, accuracy: 0.85\n",
      "[Validation]\t J_a: 1927.84, accuracy: 0.56\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2099.32, accuracy: 0.91\n",
      "[Validation]\t J_a: 1907.82, accuracy: 0.56\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2072.29, accuracy: 0.95\n",
      "[Validation]\t J_a: 1885.54, accuracy: 0.57\n",
      "7400 12600\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2335.36, accuracy: 0.63\n",
      "[Validation]\t J_a: 2049.82, accuracy: 0.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2194.44, accuracy: 0.70\n",
      "[Validation]\t J_a: 1979.67, accuracy: 0.54\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2131.89, accuracy: 0.82\n",
      "[Validation]\t J_a: 1944.89, accuracy: 0.57\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2070.74, accuracy: 0.89\n",
      "[Validation]\t J_a: 1913.37, accuracy: 0.56\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2032.45, accuracy: 0.93\n",
      "[Validation]\t J_a: 1888.43, accuracy: 0.57\n",
      "7600 12400\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2308.20, accuracy: 0.52\n",
      "[Validation]\t J_a: 2053.72, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2176.56, accuracy: 0.65\n",
      "[Validation]\t J_a: 1992.77, accuracy: 0.54\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2105.66, accuracy: 0.82\n",
      "[Validation]\t J_a: 2044.99, accuracy: 0.57\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2061.03, accuracy: 0.90\n",
      "[Validation]\t J_a: 3301.26, accuracy: 0.57\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2032.04, accuracy: 0.94\n",
      "[Validation]\t J_a: 2947.98, accuracy: 0.56\n",
      "7800 12200\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2309.56, accuracy: 0.53\n",
      "[Validation]\t J_a: 2035.75, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2180.99, accuracy: 0.69\n",
      "[Validation]\t J_a: 1989.07, accuracy: 0.55\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2096.33, accuracy: 0.82\n",
      "[Validation]\t J_a: 1993.42, accuracy: 0.58\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2059.71, accuracy: 0.89\n",
      "[Validation]\t J_a: 1965.37, accuracy: 0.57\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2031.04, accuracy: 0.94\n",
      "[Validation]\t J_a: 1969.19, accuracy: 0.58\n",
      "8000 12000\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2290.32, accuracy: 0.53\n",
      "[Validation]\t J_a: 2051.21, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2154.82, accuracy: 0.68\n",
      "[Validation]\t J_a: 1999.30, accuracy: 0.55\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2089.16, accuracy: 0.81\n",
      "[Validation]\t J_a: 1957.13, accuracy: 0.57\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2038.48, accuracy: 0.89\n",
      "[Validation]\t J_a: 1928.51, accuracy: 0.57\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 2010.04, accuracy: 0.94\n",
      "[Validation]\t J_a: 1903.84, accuracy: 0.59\n",
      "8200 11800\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2246.52, accuracy: 0.53\n",
      "[Validation]\t J_a: 2017.06, accuracy: 0.53\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2129.14, accuracy: 0.71\n",
      "[Validation]\t J_a: 1972.27, accuracy: 0.56\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2062.50, accuracy: 0.83\n",
      "[Validation]\t J_a: 1950.61, accuracy: 0.57\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2021.20, accuracy: 0.90\n",
      "[Validation]\t J_a: 1940.11, accuracy: 0.58\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1992.45, accuracy: 0.94\n",
      "[Validation]\t J_a: 1911.95, accuracy: 0.59\n",
      "8400 11600\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2289.94, accuracy: 0.55\n",
      "[Validation]\t J_a: 2085.97, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2145.27, accuracy: 0.58\n",
      "[Validation]\t J_a: 2033.07, accuracy: 0.53\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2083.32, accuracy: 0.73\n",
      "[Validation]\t J_a: 1974.51, accuracy: 0.55\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2023.46, accuracy: 0.83\n",
      "[Validation]\t J_a: 1935.75, accuracy: 0.56\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1992.35, accuracy: 0.89\n",
      "[Validation]\t J_a: 1921.82, accuracy: 0.57\n",
      "8600 11400\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2246.28, accuracy: 0.51\n",
      "[Validation]\t J_a: 2066.78, accuracy: 0.52\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2123.92, accuracy: 0.65\n",
      "[Validation]\t J_a: 1986.72, accuracy: 0.55\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2057.35, accuracy: 0.79\n",
      "[Validation]\t J_a: 1988.56, accuracy: 0.59\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 2012.50, accuracy: 0.88\n",
      "[Validation]\t J_a: 1987.53, accuracy: 0.61\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1985.09, accuracy: 0.92\n",
      "[Validation]\t J_a: 2085.75, accuracy: 0.61\n",
      "8800 11200\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2199.62, accuracy: 0.54\n",
      "[Validation]\t J_a: 2044.08, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2076.85, accuracy: 0.65\n",
      "[Validation]\t J_a: 1983.72, accuracy: 0.57\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2007.56, accuracy: 0.81\n",
      "[Validation]\t J_a: 1968.08, accuracy: 0.60\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1977.34, accuracy: 0.88\n",
      "[Validation]\t J_a: 1978.57, accuracy: 0.61\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1949.19, accuracy: 0.92\n",
      "[Validation]\t J_a: 3910.74, accuracy: 0.62\n",
      "9000 11000\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2218.69, accuracy: 0.54\n",
      "[Validation]\t J_a: 2071.82, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2084.11, accuracy: 0.59\n",
      "[Validation]\t J_a: 1996.40, accuracy: 0.53\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2015.98, accuracy: 0.74\n",
      "[Validation]\t J_a: 1964.61, accuracy: 0.56\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1966.62, accuracy: 0.83\n",
      "[Validation]\t J_a: 1931.69, accuracy: 0.57\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1937.68, accuracy: 0.89\n",
      "[Validation]\t J_a: 1929.13, accuracy: 0.57\n",
      "9200 10800\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2213.05, accuracy: 0.55\n",
      "[Validation]\t J_a: 2053.44, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2088.10, accuracy: 0.64\n",
      "[Validation]\t J_a: 1994.95, accuracy: 0.55\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 2028.90, accuracy: 0.76\n",
      "[Validation]\t J_a: 1961.71, accuracy: 0.58\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1974.23, accuracy: 0.85\n",
      "[Validation]\t J_a: 1926.15, accuracy: 0.59\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1945.21, accuracy: 0.89\n",
      "[Validation]\t J_a: 1909.31, accuracy: 0.59\n",
      "9400 10600\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2163.29, accuracy: 0.52\n",
      "[Validation]\t J_a: 2059.12, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2049.81, accuracy: 0.56\n",
      "[Validation]\t J_a: 2003.47, accuracy: 0.53\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 1980.61, accuracy: 0.72\n",
      "[Validation]\t J_a: 2007.39, accuracy: 0.56\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1938.40, accuracy: 0.82\n",
      "[Validation]\t J_a: 1995.72, accuracy: 0.57\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1912.67, accuracy: 0.88\n",
      "[Validation]\t J_a: 1941.66, accuracy: 0.57\n",
      "9600 10400\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2173.65, accuracy: 0.59\n",
      "[Validation]\t J_a: 2055.99, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2043.27, accuracy: 0.62\n",
      "[Validation]\t J_a: 1990.15, accuracy: 0.55\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 1992.25, accuracy: 0.72\n",
      "[Validation]\t J_a: 1940.39, accuracy: 0.56\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 1950.64, accuracy: 0.80\n",
      "[Validation]\t J_a: 1901.44, accuracy: 0.58\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 1915.20, accuracy: 0.85\n",
      "[Validation]\t J_a: 1876.61, accuracy: 0.59\n",
      "9800 10200\n",
      "Epoch: 0\n",
      "[Train]\t\t J_a: 2142.87, accuracy: 0.50\n",
      "[Validation]\t J_a: 2052.40, accuracy: 0.51\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 2021.48, accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "batch_size=50\n",
    "for i in range(50):\n",
    "    model = initialize_model(x_dim, y_dim, z_dim, h_dim, prior_mean, prior_var)\n",
    "    train_labelled, train_unlabelled = create_data_sets(labelled, unlabelled, batch_size)\n",
    "    \n",
    "    print(labelled[0].shape[0], unlabelled[0].shape[0])\n",
    "    error, acc = train_semi_supervised(model, train_labelled, train_unlabelled, validation[:-1], cuda, epochs=5)\n",
    "    errors.append((labelled[0].shape[0], unlabelled[0].shape[0], error, acc))\n",
    "    \n",
    "    \n",
    "    #new_data = np.random.choice(unlabelled[0].shape[0], NUM_QUERY)\n",
    "    new_data = query_new_data(NUM_QUERY, NUM_MC_SAMPLES, model, unlabelled[0], repr_scores=repr_scores[row_ids_unlabelled])\n",
    "    row_ids_unlabelled = np.delete(row_ids_unlabelled, new_data, axis=0)\n",
    "    \n",
    "    labelled, unlabelled = rearange_datasets(labelled, unlabelled, new_data)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labelled = []\n",
    "num_unlabelled = []\n",
    "cost = []\n",
    "acc = []\n",
    "\n",
    "for n_l, n_u, c, a in errors:\n",
    "    num_labelled.append(n_l)\n",
    "    num_unlabelled.append(n_u)\n",
    "    cost.append(c)\n",
    "    acc.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(num_labelled, cost)\n",
    "plt.xlabel(\"Number of labelled data\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.savefig(\"n_labelled_vs_cost-represent.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(num_labelled, acc)\n",
    "plt.xlabel(\"Number of labelled data\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.savefig(\"n_labelled_vs_acc-represent.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_2 = [(n_l, n_u, c, a.item()) for n_l, n_u, c, a in errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"IMDB-data-erros-represent.pkl\", \"wb\") as f:\n",
    "    pickle.dump(errors_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
